{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hw3 Report code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Constants\n",
    "DIRECTORY = \"ml-2018spring-hw3/\"\n",
    "MODEL_DIRECTORY = \"model/\"\n",
    "class_names = [\"Mad\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_training_data(validation_split=0.0):\n",
    "    filename = \"train.csv\"\n",
    "    filepath = DIRECTORY + filename\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        data = pd.read_csv(filepath)\n",
    "        x_raw = data[\"feature\"]\n",
    "        y_raw = data[\"label\"]\n",
    "        \n",
    "        \n",
    "        #  Split features into array & reshape to (48, 48, 1)\n",
    "        x = x_raw.str.split(expand=True).values.reshape(-1, 48, 48, 1).astype('int')\n",
    "        y = y_raw.values.astype('int')\n",
    "        \n",
    "        # Split validation set\n",
    "        if validation_split > 0.0 and validation_split <= 1.0:\n",
    "            valid_size = int(validation_split*len(x))\n",
    "            x_train = x[:-valid_size]\n",
    "            x_valid = x[-valid_size:]\n",
    "            y_train = y[:-valid_size]\n",
    "            y_valid = y[-valid_size:]\n",
    "        else:\n",
    "            x_train = x\n",
    "            y_train = y\n",
    "            x_valid = []\n",
    "            y_valid = []\n",
    "    else:\n",
    "        print(\"Error: No such file at %s\" % filepath)\n",
    "\n",
    "    return (x_train, y_train), (x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid)= get_training_data(validation_split=0.1)\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255\n",
    "mean, std = np.load(\"dist.npy\")\n",
    "x_train = (x_train - mean) / std\n",
    "x_valid = (x_valid - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIRECTORY + \"model.h5\"\n",
    "model = load_model(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confunsion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(x_valid)\n",
    "y_pred = np.argmax(prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"history/baseline.pickle\", \"rb\") as f:\n",
    "    train_history_bl = pickle.load(f)\n",
    "with open(\"history/norm.pickle\", \"rb\") as f:\n",
    "    train_history_norm = pickle.load(f)\n",
    "with open(\"history/aug.pickle\", \"rb\") as f:\n",
    "    train_history_aug = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_history_bl[\"val_acc\"])\n",
    "plt.plot(train_history_norm[\"val_acc\"])\n",
    "plt.title(\"Train History (Normalization comparison)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"w/o normalization\", \"w/ normalization\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w/o normalization acc: %s\" % max(train_history_bl['val_acc']))\n",
    "print(\"w/ normalization acc: %s\" % max(train_history_norm['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_history_bl[\"val_acc\"])\n",
    "plt.plot(train_history_aug[\"val_acc\"])\n",
    "plt.title(\"Train History (Augmentation comparison)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"w/o augmentation\", \"w/ augmentation\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w/o augmentation acc: %s\" % max(train_history_bl['val_acc']))\n",
    "print(\"w/ augmentation acc: %s\" % max(train_history_aug['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "private_pixels = x_train\n",
    "emotion_classifier = model\n",
    "input_img = emotion_classifier.input\n",
    "img_ids = [-698]\n",
    "\n",
    "for idx in img_ids:\n",
    "    img = private_pixels[idx].reshape(-1, 48, 48, 1)\n",
    "    val_proba = emotion_classifier.predict(img)\n",
    "    pred = val_proba.argmax(axis=-1)\n",
    "    target = K.mean(emotion_classifier.output[:, pred])\n",
    "    grads = K.gradients(target, input_img)[0]\n",
    "    fn = K.function([input_img, K.learning_phase()], [grads])\n",
    "\n",
    "    heatmap = fn([img, 0])[0].reshape(48, 48, 1)\n",
    "    # Set all gradient to positive\n",
    "    heatmap = np.abs(heatmap)\n",
    "    # Normalize distribution\n",
    "    heatmap = (heatmap - heatmap.mean()) / (heatmap.std() + 1e-5)\n",
    "    # Ensure std is 0.1\n",
    "    heatmap *= 0.1\n",
    "    # Clip to [0, 1]\n",
    "    heatmap += 0.5\n",
    "    heatmap = np.clip(heatmap, 0, 1)\n",
    "    heatmap = heatmap.reshape(48, 48)\n",
    "    heatmap /= heatmap.max()\n",
    "\n",
    "    thres = 0.5\n",
    "    orig = private_pixels[idx].reshape(48, 48)\n",
    "    see = np.copy(orig)\n",
    "    see[np.where(heatmap <= thres)] = np.mean(see)\n",
    "\n",
    "    # Original image\n",
    "    plt.figure()\n",
    "    plt.imshow(orig, cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    plt.draw()\n",
    "    # fig.savefig(os.path.join(cmap_dir, 'privateTest', '{}.png'.format(idx)), dpi=100)\n",
    "    \n",
    "    # Saliency map\n",
    "    plt.figure()\n",
    "    plt.imshow(heatmap, cmap=plt.cm.jet)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    plt.draw()\n",
    "    # fig.savefig(os.path.join(cmap_dir, 'privateTest', '{}.png'.format(idx)), dpi=100)\n",
    "\n",
    "    # Mask original image\n",
    "    plt.figure()\n",
    "    plt.imshow(see, cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    plt.draw()\n",
    "    # fig.savefig(os.path.join(partial_see_dir, 'privateTest', '{}.png'.format(idx)), dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用梯度遞增法，找出最能激活特定filter的圖片(從白噪音開始)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-7)\n",
    "\n",
    "def grad_ascent(num_step,input_image_data,iter_func):\n",
    "    # https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n",
    "    step_size = 1e-2\n",
    "    filter_images = []\n",
    "    for i in range(num_step):\n",
    "        loss_value, grads_value = iter_func([input_image_data])\n",
    "        input_image_data += grads_value * step_size\n",
    "        if i % RECORD_FREQ == 0:\n",
    "            filter_images.append((input_image_data, loss_value))\n",
    "    return filter_images\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "emotion_classifier = model\n",
    "layer_dict = dict([layer.name, layer] for layer in emotion_classifier.layers)\n",
    "input_img = emotion_classifier.input\n",
    "\n",
    "name_ls = [\"leaky_re_lu_5\"]\n",
    "collect_layers = [layer_dict[name].output for name in name_ls]\n",
    "num_step = NUM_STEPS = 50\n",
    "RECORD_FREQ = 10\n",
    "nb_filter = 16\n",
    "\n",
    "for cnt, c in enumerate(collect_layers):\n",
    "    filter_imgs = []\n",
    "    for filter_idx in range(nb_filter):\n",
    "        input_img_data = np.random.random((1, 48, 48, 1)) # random noise\n",
    "        target = K.mean(c[:, :, :, filter_idx])\n",
    "        grads = normalize(K.gradients(target, input_img)[0])\n",
    "        iterate = K.function([input_img], [target, grads])\n",
    "\n",
    "        filter_imgs.append(grad_ascent(num_step, input_img_data, iterate))\n",
    "    \n",
    "    for it in range(NUM_STEPS//RECORD_FREQ):\n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        for i in range(nb_filter):\n",
    "            ax = fig.add_subplot(nb_filter/16, 16, i+1)\n",
    "            img = filter_imgs[i][it][0].squeeze()\n",
    "            ax.imshow(img, cmap='PuBu')\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "            plt.xlabel('{:.3f}'.format(filter_imgs[i][it][1]))\n",
    "            plt.tight_layout()\n",
    "        fig.suptitle('Filters of layer {} (# Ascent Epoch {} )'.format(name_ls[cnt], it*RECORD_FREQ))\n",
    "        # img_path = os.path.join(filter_dir, '{}-{}'.format(store_path, name_ls[cnt]))\n",
    "        # if not os.path.isdir(img_path):\n",
    "        #    os.mkdir(img_path)\n",
    "        # fig.savefig(os.path.join(img_path,'e{}'.format(it*RECORD_FREQ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 給定輸入圖片，取出特定層的輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ls = [\"conv2d_5\", \"leaky_re_lu_5\"]\n",
    "collect_layers = [K.function([input_img, K.learning_phase()], [layer_dict[name].output]) for name in name_ls]\n",
    "\n",
    "choose_id = 17\n",
    "photo = private_pixels[choose_id].reshape(-1, 48, 48, 1)\n",
    "for cnt, fn in enumerate(collect_layers):\n",
    "    im = fn([photo, 0]) #get the output of that layer\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    # nb_filter = im[0].shape[3]\n",
    "    nb_filter = 32\n",
    "    for i in range(nb_filter):\n",
    "        ax = fig.add_subplot(nb_filter/16, 16, i+1)\n",
    "        ax.imshow(im[0][0, :, :, i], cmap='PuBu')\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "        plt.tight_layout()\n",
    "    fig.suptitle('Output of layer{} (Given image{})'.format(cnt, choose_id))\n",
    "    # img_path = os.path.join(vis_dir, store_path)\n",
    "    # if not os.path.isdir(img_path):\n",
    "    #     os.mkdir(img_path)\n",
    "    # fig.savefig(os.path.join(img_path,'layer{}'.format(cnt)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
