{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVrA1PL_b6uL"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqQW-t4Xb6uM"
   },
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zpFXVRuAb6uN"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "!pip install -q keras==2.0.8\n",
    "!pip install -q gensim==3.1.0\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WDJsLPFRb6uR"
   },
   "outputs": [],
   "source": [
    "LABEL_TRAINING_PATH = \"drive/ml-2018spring-hw5/training_label.txt\"\n",
    "UNLABEL_TRAINING_PATH = \"drive/ml-2018spring-hw5/training_nolabel.txt\"\n",
    "TESTING_PATH = \"drive/ml-2018spring-hw5/testing_data.txt\"\n",
    "STOPLIST_PATH = \"drive/stoplist.txt\"\n",
    "WORD2VEC_MODEL_PATH = \"drive/word2vec.model\"\n",
    "RNN_MODEL_PATH = \"drive/rnn_semi4real.h5\"\n",
    "OUTPUT_PATH = \"drive/output.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jI3owDnOb6uT"
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PR5z0bgFb6uT"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, LSTM, Dropout, GRU, average, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import logging\n",
    "import string\n",
    "import itertools\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Logging config\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "EMBED_DIM = 300\n",
    "DICT_SIZE = 30000\n",
    "MAX_SENT_LEN = 40\n",
    "REMOVE_PUNC = False\n",
    "REMOVE_STOPWORDS = False\n",
    "REMOVE_DUPLICHAR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgk7GXZFb6uW"
   },
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MfOEwTSrb6uX"
   },
   "outputs": [],
   "source": [
    "LABEL_TRAINING_PATH = \"ml-2018spring-hw5/training_label.txt\"\n",
    "UNLABEL_TRAINING_PATH = \"ml-2018spring-hw5/training_nolabel.txt\"\n",
    "TESTING_PATH = \"ml-2018spring-hw5/testing_data.txt\"\n",
    "STOPLIST_PATH = \"model/stoplist.txt\"\n",
    "WORD2VEC_MODEL_PATH = \"model/word2vec.model\"\n",
    "RNN_MODEL_PATH = \"model/rnn.h5\"\n",
    "OUTPUT_PATH = \"output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yXzB6g-Nb6uZ"
   },
   "outputs": [],
   "source": [
    "def get_label_training_data():\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    with open(LABEL_TRAINING_PATH, 'r') as file:\n",
    "        for line in file:\n",
    "            label, text = line.strip().split(\" +++$+++ \")\n",
    "            if REMOVE_PUNC:\n",
    "                text = remove_punctuation(text)\n",
    "            X_train.append(text)\n",
    "            y_train.append(int(label))\n",
    "    if REMOVE_STOPWORDS:\n",
    "        X_train = remove_stopwords(X_train)\n",
    "    if REMOVE_DUPLICHAR:\n",
    "        X_train = remove_duplichar(X_train)\n",
    "    return X_train, y_train\n",
    "\n",
    "def get_unlabel_training_data():\n",
    "    X_train = []\n",
    "\n",
    "    with open(UNLABEL_TRAINING_PATH, 'r') as file:\n",
    "        for line in file:\n",
    "            text = line.strip()\n",
    "            if REMOVE_PUNC:\n",
    "                text = remove_punctuation(text)\n",
    "            X_train.append(text)\n",
    "    if REMOVE_STOPWORDS:\n",
    "        X_train = remove_stopwords(X_train)\n",
    "    if REMOVE_DUPLICHAR:\n",
    "        X_train = remove_duplichar(X_train)\n",
    "    return X_train\n",
    "\n",
    "def get_testing_data():\n",
    "    X_test = []\n",
    "    \n",
    "    with open(TESTING_PATH, 'r') as file:\n",
    "        # Ignore header\n",
    "        file.readline()\n",
    "        for line in file:\n",
    "            no, text = line.strip().split(',', 1)\n",
    "            if REMOVE_PUNC:\n",
    "                text = remove_punctuation(text)\n",
    "            X_test.append(text)\n",
    "    if REMOVE_STOPWORDS:\n",
    "        X_test = remove_stopwords(X_test)\n",
    "    if REMOVE_DUPLICHAR:\n",
    "        X_test = remove_duplichar(X_test)\n",
    "    return X_test\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_stopwords(X):\n",
    "    \"\"\"\n",
    "    Remove stopwords and split sentence to words\n",
    "    \"\"\"\n",
    "    stoplist = set('')\n",
    "    X_ = [[word for word in sentence.split() if word not in stoplist] for sentence in X]\n",
    "    return X_\n",
    "\n",
    "def remove_duplichar(X):\n",
    "    \"\"\"\n",
    "    Remove duplicate characters\n",
    "    \"\"\"\n",
    "    for i, text in enumerate(X):\n",
    "        X[i] = [''.join(ch for ch, _ in itertools.groupby(word)) for word in text]\n",
    "    return X\n",
    "\n",
    "def preprocess(string):\n",
    "    # Remove duplicate (over 3 times) char, ex. 'heeeeelloooo' -> 'hello'\n",
    "    # string = re.sub(r\"(\\w)\\1{2,}\", r'\\1', string)\n",
    "    string = re.sub(r\"(.)\\1{2,}\", r'\\1', string)\n",
    "    return string\n",
    "    \n",
    "def output_file(output):\n",
    "    with open(OUTPUT_PATH, 'w') as file:\n",
    "        file.write(\"id,label\\n\")\n",
    "        file.write('\\n'.join(['{},{}'.format(index, label) for index, label in enumerate(output)]))\n",
    "        \n",
    "def word2sent(X):\n",
    "    for i, v in enumerate(X):\n",
    "        X[i] = ' '.join(v)\n",
    "    return X\n",
    "\n",
    "def sent2word(X):\n",
    "    for i in range(len(X)):\n",
    "        X[i] = [word for word in X[i].split()]\n",
    "    return X\n",
    "\n",
    "def split_data(X, y, frac=0.1):\n",
    "    val_size = int(len(X)*frac)\n",
    "    return (X[:-val_size], y[:-val_size]), (X[-val_size:], y[-val_size:])\n",
    "\n",
    "def get_semi_data(label, threshold):\n",
    "    index = (label>1-threshold) + (label<threshold)\n",
    "    y = np.round(label[index])\n",
    "    return np.where(index), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikKaKTPGb6uc"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "09pmPPI3b6uc"
   },
   "outputs": [],
   "source": [
    "X_label, y_label = get_label_training_data()\n",
    "X_unlabel = get_unlabel_training_data()\n",
    "# X_label = [preprocess(sent) for sent in X_label]\n",
    "# X_unlabel = [preprocess(sent) for sent in X_unlabel]\n",
    "X_all = X_label + X_unlabel\n",
    "X_test = get_testing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27971,
     "status": "ok",
     "timestamp": 1527501315894,
     "user": {
      "displayName": "陳代穎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111397455373110644999"
     },
     "user_tz": -480
    },
    "id": "TGRFfbn6b6uf",
    "outputId": "b25b32de-c70f-40dc-eebd-83ad3fb55a7a"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=DICT_SIZE)\n",
    "tokenizer.fit_on_texts(X_all)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X_label)\n",
    "X = pad_sequences(X, maxlen=MAX_SENT_LEN)\n",
    "X_semi = tokenizer.texts_to_sequences(X_unlabel)\n",
    "X_semi = pad_sequences(X_semi, maxlen=MAX_SENT_LEN)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = split_data(X, y_label, frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZaITSjQb6uf"
   },
   "source": [
    "## Train word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15473,
     "status": "ok",
     "timestamp": 1527500653742,
     "user": {
      "displayName": "陳代穎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111397455373110644999"
     },
     "user_tz": -480
    },
    "id": "Te6iYHE6b6uo",
    "outputId": "e163b902-f96b-4183-d82f-2b3b96063578"
   },
   "outputs": [],
   "source": [
    "X_train_w2v = sent2word(X_train_label+X_train_unlabel)\n",
    "w2v_model = word2vec.Word2Vec(X_train_w2v, size=EMBED_DIM)\n",
    "w2v_model.save(WORD2VEC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xv2r_VF7b6uq"
   },
   "source": [
    "### Load word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1527501318059,
     "user": {
      "displayName": "陳代穎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111397455373110644999"
     },
     "user_tz": -480
    },
    "id": "dzLjv7HWb6uq",
    "outputId": "20afee41-b8f4-458c-a54e-0ed47a45b6c3"
   },
   "outputs": [],
   "source": [
    "w2v_model = word2vec.Word2Vec.load(WORD2VEC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9-89el-b6us"
   },
   "source": [
    "### Embegging matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "b2-Q47t2b6ut"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for k, v in w2v_model.wv.vocab.items():\n",
    "    embeddings_index[k] = w2v_model.wv[k]\n",
    "\n",
    "embedding_matrix = np.zeros((DICT_SIZE + 1, EMBED_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > DICT_SIZE:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jj6_hnaGb6uu"
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3569,
     "status": "ok",
     "timestamp": 1527501348782,
     "user": {
      "displayName": "陳代穎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111397455373110644999"
     },
     "user_tz": -480
    },
    "id": "3LQtwF9qb6uw",
    "outputId": "c5dc58ab-d0b6-43f4-d519-b7c8fadd127a"
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SENT_LEN,), dtype='int32')\n",
    "\n",
    "# Embedding\n",
    "embedded_sequences = Embedding(len(embedding_matrix),\n",
    "                            EMBED_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)(sequence_input)\n",
    "# RNN\n",
    "output = Bidirectional(GRU(512,\n",
    "             return_sequences=True,\n",
    "             dropout=0.3))(embedded_sequences)\n",
    "output = GRU(256,\n",
    "             return_sequences=False,\n",
    "             dropout=0.3)(output)\n",
    "# DNN\n",
    "output = Dense(256,\n",
    "               activation='relu',\n",
    "               kernel_regularizer=regularizers.l2(0.1))(output)\n",
    "output = Dropout(0.3)(output)\n",
    "preds = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(RNN_MODEL_PATH,\n",
    "                             monitor=\"val_acc\",\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdMrvD4wh6C1"
   },
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jvc3WgjtZiVO"
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(DICT_SIZE,))\n",
    "\n",
    "# DNN\n",
    "output = Dense(256,\n",
    "               activation='relu',\n",
    "               kernel_regularizer=regularizers.l2(0.1))(sequence_input)\n",
    "output = Dropout(0.3)(output)\n",
    "preds = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(RNN_MODEL_PATH,\n",
    "                             monitor=\"val_acc\",\n",
    "                             verbose=1,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5mVOLXcb6u1"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4513397,
     "status": "ok",
     "timestamp": 1527505862198,
     "user": {
      "displayName": "陳代穎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111397455373110644999"
     },
     "user_tz": -480
    },
    "id": "hUIVkvf5jdt-",
    "outputId": "20880cc6-35e4-4466-90f5-9016e9c58bd3"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wf_3tN6TJCLV"
   },
   "source": [
    "### Semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PDZxGmL7b6uz"
   },
   "outputs": [],
   "source": [
    "account = np.array([[None, 0] for i in range(len(X_semi))]) # [label, count]\n",
    "\n",
    "for i in range(10):\n",
    "    print ('-- iteration %d  X_train size: %d' %(i+1, len(X_train)))\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=2,\n",
    "                    batch_size=128,\n",
    "                    callbacks=[checkpoint])\n",
    "    \n",
    "    y_semi = model.predict(X_semi, batch_size=1024, verbose=True)\n",
    "    y_semi = np.squeeze(y_semi)\n",
    "    indices, label = get_semi_data(y_semi, 0.05)\n",
    "    transfer_set = []\n",
    "    \n",
    "    for j, index in enumerate(indices):\n",
    "        if account[index][0] == None:\n",
    "            account[index][0] = label[j]\n",
    "        elif account[index][0] != label[j]: # Unstable labeling\n",
    "            account[index][1] = 0\n",
    "        account[index][1] += 1\n",
    "        if account[index][1] >= accum_num:\n",
    "            transfer_set.append(index)\n",
    "    \n",
    "    if len(semi_set) > 0:\n",
    "        # Append semi data to training data\n",
    "        X_train = np.append(X_train, X_semi[transfer_set], 0)\n",
    "        y_train = np.append(y_train, account[transfer_set, 0])\n",
    "        # Delete those data from semi data\n",
    "        X_semi = np.delete(X_semi, transfer_set, 0)\n",
    "        account = np.delete(account, transfer_set, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVwpHka4jiok"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UygVTxD8HCYY"
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 84156,
     "status": "ok",
     "timestamp": 1527500426537,
     "user": {
      "displayName": "陳代穎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111397455373110644999"
     },
     "user_tz": -480
    },
    "id": "flPnUXNfb6u2",
    "outputId": "2393607d-2f64-4d40-b040-9fbc194c24b5"
   },
   "outputs": [],
   "source": [
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=MAX_SENT_LEN)\n",
    "y_test = model.predict(X_test, batch_size=1024, verbose=True)\n",
    "\n",
    "y = np.around(y_test).astype(np.int32).flatten()\n",
    "output_file(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pca4k7xAHFql"
   },
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g0gymJ1UcOXt"
   },
   "outputs": [],
   "source": [
    "model.load_weights(RNN_MODEL_PATH)\n",
    "\n",
    "X_test = tokenizer.texts_to_matrix(X_test, mode=\"count\")\n",
    "y_test = model.predict(X_test, batch_size=1024, verbose=True)\n",
    "\n",
    "y = np.around(y_test).astype(np.int32).flatten()\n",
    "output_file(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0oz57bsoVqw"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uJrGZ48YoU3L"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def ensemble_models(models, model_input):\n",
    "    # Collect outputs of models in a list\n",
    "    y_models = [model(model_input) for model in models]\n",
    "    \n",
    "    # Averaging outputs\n",
    "    y_avg = average(y_models)\n",
    "    \n",
    "    model_ens = Model(inputs=model_input, outputs=y_avg, name='ensemble')\n",
    "    \n",
    "    return model_ens\n",
    "\n",
    "models = [model_1, model_2, model_3]\n",
    "model_input = Input(shape=models[0].input_shape[1:])\n",
    "model_ens = ensemble_models(models, model_input)\n",
    "model_ens.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_ens.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mEjSLd7wreOa"
   },
   "outputs": [],
   "source": [
    "label = model_ens.predict(X_test, batch_size=1024, verbose=True)\n",
    "label = np.squeeze(label)\n",
    "y_test = np.around(label).astype(np.int32)\n",
    "output_file(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "J_CGpsXWuV7o"
   },
   "outputs": [],
   "source": [
    "model_ens.save(\"drive/ensemble.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DB59hBrGinC"
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ha1D12_tlrjb"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "text = [\"today is a good day, but it is hot\", \"today is hot, but it is a good day\"]\n",
    "text = tokenizer.texts_to_sequences(text)\n",
    "seq = pad_sequences(text, maxlen=MAX_SENT_LEN)\n",
    "result = model.predict(seq)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aoJucxE0jojK"
   },
   "outputs": [],
   "source": [
    "text = [\"today is a good day, but it is hot\", \"today is hot, but it is a good day\"]\n",
    "text = tokenizer.texts_to_matrix(text, mode=\"count\")\n",
    "result = model.predict(text)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "M0oz57bsoVqw",
    "NqNoikcLb6u4"
   ],
   "default_view": {},
   "name": "hw5_train.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
