{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "height = width = 28\n",
    "IMAGE_PATH = \"ml2018spring-hw4-v2/image.npy\"\n",
    "TEST_CASE_PATH = \"ml2018spring-hw4-v2/test_case.csv\"\n",
    "OUTPUT_PATH = \"output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X_train = np.load(IMAGE_PATH)\n",
    "\n",
    "# Load test case\n",
    "with open(TEST_CASE_PATH, 'r') as file:\n",
    "    content = file.read().strip('\\n').replace(',', ' ').split()[3:]\n",
    "    X_test = []\n",
    "    for i in range(0, len(content), 3):\n",
    "        X_test.append((content[i+1], content[i+2]))\n",
    "        \n",
    "    X_test = np.array(X_test).astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-craft PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_train_norm = X_train / 255\n",
    "\n",
    "# Covariance matrix\n",
    "cov_mat = np.cov(X_train_norm.T)\n",
    "# Eigenvalues and Eigenvectors\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "# Plot principal components \n",
    "eigen_vals_sum = np.sum(eigen_vals)\n",
    "eigen_vals_frac = [i / eigen_vals_sum for i in sorted(eigen_vals, reverse=True)]\n",
    "eigen_vals_cum = np.cumsum(eigen_vals_frac)\n",
    "\n",
    "plt.bar(range(0, len(eigen_vals_frac)),\n",
    "        eigen_vals_frac, alpha=0.5, \n",
    "        align='center', \n",
    "        label='individual explained variance')\n",
    "plt.step(range(0, len(eigen_vals_cum)), \n",
    "         eigen_vals_cum, \n",
    "         where='mid', \n",
    "         label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sort eigenvalues\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "\n",
    "# Get reduction dimension\n",
    "cum_bound = 0.8\n",
    "for key, value in enumerate(eigen_vals_cum):\n",
    "    if value >= 0.8:\n",
    "        cum_index = key\n",
    "        break\n",
    "        \n",
    "# Projection matrix\n",
    "w = []\n",
    "for i in range(cum_index): \n",
    "    w.append(eigen_pairs[i][1])\n",
    "w = np.array(w)\n",
    "\n",
    "# Dimension reduction\n",
    "X_train_pca = np.dot(w, X_train.T)\n",
    "X_train_pca = X_train_pca.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalization\n",
    "X_train_norm = X_train / 255\n",
    "\n",
    "pca = PCA(n_components=395, whiten=True)\n",
    "X_train_pca = pca.fit_transform(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inv = pca.inverse_transform(X_train_pca)\n",
    "exp_var_ratio = pca.explained_variance_ratio_\n",
    "exp_var_cum = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 103\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train_inv[index].reshape(28, 28))\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_train[index].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar(range(0, len(exp_var_ratio)), exp_var_ratio, alpha=0.5, align='center', label='individual explained variance')\n",
    "plt.step(range(0, len(exp_var_cum)), exp_var_cum, where='mid', label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_image = pca.components_[120]\n",
    "eigen_image -= np.min(eigen_image)\n",
    "eigen_image /= np.max(eigen_image)\n",
    "eigen_image = (eigen_image * 255).astype(np.uint8).reshape(height, width)\n",
    "plt.imshow(eigen_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2, n_iter=250).fit_transform(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"X_embedded\", X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_train_pca)\n",
    "X_train_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(X_embedded[X_train_labels == 0][:, 0], X_embedded[X_train_labels == 0][:, 1], c='r')\n",
    "plt.scatter(X_embedded[X_train_labels == 1][:, 0], X_embedded[X_train_labels == 1][:, 1], c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to file\n",
    "output = []\n",
    "cnt = 0\n",
    "for i, j in X_test:\n",
    "    if X_train_labels[i] == X_train_labels[j]:\n",
    "        cnt += 1\n",
    "        output.append(1)\n",
    "    else:\n",
    "        output.append(0)\n",
    "print(cnt)\n",
    "        \n",
    "# with open(OUTPUT_PATH, 'w') as file:\n",
    "#     file.write(\"ID,Ans\\n\")\n",
    "#     file.write('\\n'.join(['{},{}'.format(index, element) for index, element in enumerate(output)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
